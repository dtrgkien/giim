# GIIM: Graph-based Learning of Inter- and Intra-view Dependencies for Multi-view Medical Image Diagnosis

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Official PyTorch implementation of GIIM for multi-view medical image diagnosis with robust missing view handling.**

<p align="center">
  <img src="docs/assets/giim_architecture.png" alt="GIIM Architecture" width="800"/>
</p>

---

## âš ï¸ Repository Status

**This is a pre-release version pending license and permission review.**

This repository currently contains documentation, model architecture descriptions, and configuration examples. Full implementation will be released upon completion of institutional review.

### ğŸ“‹ Component Status

| Component | Status | Description |
|-----------|--------|-------------|
| **Documentation** | âœ… Complete | Full paper documentation and architecture details |
| **Configuration Files** | âœ… Complete | YAML configs for all datasets |
| **Installation Guide** | âœ… Complete | Detailed installation instructions |
| **API Documentation** | âœ… Complete | Complete API and usage examples |
| **License & Citation** | âœ… Complete | MIT License and citation information |
| **Model Architecture** | âœ… Complete | Detailed architecture documentation |
| **Dataset Documentation** | âœ… Complete | Dataset preparation guidelines |
| | | |
| **Model Implementation** | âŒ Pending | GNN model, graph builder, feature extractor |
| **Training Code** | âŒ Pending | Training loops and optimization |
| **Evaluation Code** | âŒ Pending | Evaluation metrics and protocols |
| **Data Loaders** | âŒ Pending | Dataset loading and preprocessing |
| **Utility Functions** | âŒ Pending | Missing view imputation implementations |
| **Training Scripts** | âŒ Pending | End-to-end training scripts |
| **Pre-trained Weights** | âŒ Pending | Model checkpoints for reproduction |
| **Example Datasets** | âŒ Pending | Sample data for testing |
| **Full Test Suite** | âŒ Pending | Comprehensive unit and integration tests |

**Expected Release:** Full implementation will be released following institutional approval and paper publication (estimated Q1 2026).

For questions about the release timeline, please open an issue or contact the authors.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Repository Structure](#repository-structure)
- [Usage](#usage)
- [Datasets](#datasets)
- [Model Architecture](#model-architecture)
- [Experiments](#experiments)
- [Citation](#citation)
- [License](#license)
- [Acknowledgments](#acknowledgments)

## ğŸ”¬ Overview

Computer-aided diagnosis (CADx) has become vital in medical imaging, but automated systems often struggle to replicate the nuanced process of clinical interpretation. Expert diagnosis requires a comprehensive analysis of how abnormalities relate to each other across various views and time points, but current multi-view CADx methods frequently overlook these complex dependencies.

**GIIM** addresses these gaps by reframing the diagnostic task as one of relationship modeling:

1. **Heterogeneous Graph Neural Networks** - Uniquely designed to simultaneously capture both critical intra-view dependencies between abnormalities and inter-view dynamics
2. **Advanced Imputation Strategies** - Four methods including RAG (Retrieval-Augmented Generation) and covariance-based approaches to handle missing data
3. **Robust Performance** - Ensures diagnostic robustness across varying missing-view rates (0-100%) in clinical scenarios

### Key Contributions

- ğŸ§  Novel graph-based approach that models crucial relationships within a single view and dynamic changes across different views
- ğŸ”„ Four imputation methods: Constant, Learnable, RAG, and Covariance-based for handling incomplete data
- ğŸ“Š Comprehensive evaluation on diverse imaging modalities: CT, MRI, and mammography
- ğŸ¯ Significantly enhanced diagnostic accuracy and robustness over existing methods

## ğŸš€ Installation

### Prerequisites

- Python >= 3.8
- CUDA-capable GPU (recommended)
- 16GB+ RAM

### Option 1: Install from source (recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/giim.git
cd giim

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e .
```

### Option 2: Install from PyPI (when available)

```bash
pip install giim
```

### Option 3: Install dependencies manually

```bash
pip install -r requirements.txt
```

### Verify Installation

```bash
python -c "import torch; import torch_geometric; import giim; print('Installation successful!')"
```

## âš¡ Quick Start

**Note:** This section describes the intended usage. Full implementation is pending release.

### 1. Review Documentation

Currently available:
- [Architecture Documentation](docs/architecture.md) - Detailed model architecture
- [Dataset Documentation](docs/datasets.md) - Dataset preparation guidelines  
- [Configuration Examples](configs/) - YAML configuration files

### 2. Explore Configuration Files

Review the provided configuration examples:

```bash
configs/
â”œâ”€â”€ default.yaml           # Default configuration template
â”œâ”€â”€ liver_ct.yaml          # Liver CT dataset configuration
â”œâ”€â”€ vin_dr_mammo.yaml      # VinDr-Mammo dataset configuration
â””â”€â”€ breastdm.yaml          # BreastDM dataset configuration
```

Example configuration structure:

```yaml
dataset:
  name: "liver_ct"
  data_path: "./data/"
  views:
    liver_ct: ["arterial", "venous", "delay"]
  
model:
  in_dim: 769  # ConvNeXt features (768) + bias (1)
  hidden_dims: [512, 256, 128, 64]
  num_classes: 4
  num_views: 3

training:
  learning_rate: 0.001
  batch_size: 8
  epochs: 100
  device: "cuda"
```

### 3. Prepare Your Data Structure

Organize your data following this structure (see [docs/datasets.md](docs/datasets.md) for details):

```
data/
â”œâ”€â”€ liver_ct/
â”‚   â”œâ”€â”€ train.csv          # Columns: patient_id, lesion_id, label, [view]_path
â”‚   â”œâ”€â”€ val.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ images/
â”‚       â”œâ”€â”€ patient1_lesion1_venous.png
â”‚       â”œâ”€â”€ patient1_lesion1_arterial.png
â”‚       â””â”€â”€ ...
â”œâ”€â”€ vin_dr_mammo/
â”‚   â””â”€â”€ ...
â””â”€â”€ breastdm/
    â””â”€â”€ ...
```

### 4. Intended API Usage (Implementation Pending)

Once released, the training workflow will be:

```bash
# Using the training script
python scripts/train.py --config configs/default.yaml
```

Or programmatically:

```python
from giim import GIIMModel, DatasetLoader, FeatureExtractor, GraphBuilder, Trainer

# Load configuration and initialize components
# (Full implementation pending release)
```

## ğŸ“ Repository Structure

```
giim/
â”œâ”€â”€ giim/                          # Main package
â”‚   â”œâ”€â”€ __init__.py               # Package initialization
â”‚   â”œâ”€â”€ dataset_loader.py         # Data loading and preprocessing
â”‚   â”œâ”€â”€ feature_extractor.py     # ConvNeXt feature extraction
â”‚   â”œâ”€â”€ graph_builder.py          # Heterogeneous graph construction
â”‚   â”œâ”€â”€ giim_model.py             # GIIM model implementation
â”‚   â”œâ”€â”€ trainer.py                # Training loop and optimization
â”‚   â”œâ”€â”€ evaluation.py             # Evaluation metrics and protocols
â”‚   â””â”€â”€ utils.py                  # Missing view imputation utilities
â”œâ”€â”€ configs/                       # Configuration files
â”‚   â”œâ”€â”€ default.yaml              # Default configuration
â”‚   â”œâ”€â”€ liver_ct.yaml             # Liver CT specific config
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/                       # Utility scripts
â”‚   â”œâ”€â”€ train.py                  # Training script
â”‚   â”œâ”€â”€ evaluate.py               # Evaluation script
â”‚   â””â”€â”€ preprocess_data.py        # Data preprocessing
â”œâ”€â”€ examples/                      # Example notebooks and scripts
â”‚   â”œâ”€â”€ quick_start.ipynb         # Quick start tutorial
â”‚   â”œâ”€â”€ custom_dataset.ipynb      # Adding custom datasets
â”‚   â””â”€â”€ visualization.ipynb       # Result visualization
â”œâ”€â”€ tests/                         # Unit tests
â”‚   â”œâ”€â”€ test_dataset_loader.py
â”‚   â”œâ”€â”€ test_graph_builder.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ architecture.md           # Architecture details
â”‚   â”œâ”€â”€ datasets.md               # Dataset documentation
â”‚   â””â”€â”€ api/                      # API documentation
â”œâ”€â”€ data/                          # Data directory (not in git)
â”œâ”€â”€ checkpoints/                   # Model checkpoints (not in git)
â”œâ”€â”€ logs/                          # Training logs (not in git)
â”œâ”€â”€ setup.py                       # Package setup
â”œâ”€â”€ pyproject.toml                # Project configuration
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ LICENSE                       # MIT License
â”œâ”€â”€ CITATION.bib                  # Citation information
â”œâ”€â”€ CONTRIBUTING.md               # Contribution guidelines
â””â”€â”€ .gitignore                    # Git ignore file
```

## ğŸ’» Intended Usage (Implementation Pending)

This section describes the intended API design. Full implementation will be available upon release.

### Planned API: Basic Training

```python
from giim import DatasetLoader, FeatureExtractor, GraphBuilder, GIIMModel, Trainer
import yaml

# Load configuration
with open('configs/default.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Initialize components
dataset_loader = DatasetLoader(config)
feature_extractor = FeatureExtractor(config)
graph_builder = GraphBuilder(config['dataset']['name'])

# Create model
model = GIIMModel(
    in_dim=769,
    hidden_dims=[512, 256, 128, 64],
    num_classes=4,
    num_views=3
)

# Load data
train_data = dataset_loader.load_data("liver_ct", "train")
val_data = dataset_loader.load_data("liver_ct", "val")

# Train
trainer = Trainer(model, train_data, val_data, config, 
                 feature_extractor, graph_builder)
trainer.train()
```

### Planned API: Custom Configuration

```python
config = {
    'dataset': {
        'name': 'liver_ct',
        'data_path': './data/',
        'views': {'liver_ct': ['arterial', 'venous', 'delay']}
    },
    'model': {
        'in_dim': 769,
        'hidden_dims': [512, 256, 128, 64],
        'num_classes': 4,
        'num_views': 3
    },
    'training': {
        'learning_rate': 0.001,
        'batch_size': 8,
        'epochs': 100,
        'device': 'cuda'
    }
}
```

### Planned API: Inference

```python
import torch
from giim import GIIMModel, FeatureExtractor, GraphBuilder

# Load trained model
model = GIIMModel(in_dim=769, hidden_dims=[512, 256, 128, 64], 
                 num_classes=4, num_views=3)
checkpoint = torch.load('checkpoints/giim_best.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Extract features
feature_extractor = FeatureExtractor(config)
features = {
    'venous': feature_extractor.extract_features(venous_image, patient_id, 'venous'),
    'arterial': feature_extractor.extract_features(arterial_image, patient_id, 'arterial'),
    'delay': feature_extractor.extract_features(delay_image, patient_id, 'delay')
}

# Build graph
graph_builder = GraphBuilder("liver_ct")
graph = graph_builder.build_graph(patient_data, features)

# Inference
with torch.no_grad():
    logits = model(graph)
    predictions = torch.argmax(logits, dim=1)
```

**Note:** The above code examples demonstrate the planned API structure. See [docs/architecture.md](docs/architecture.md) for detailed component descriptions.

## ğŸ“Š Datasets

GIIM has been evaluated on three medical imaging datasets:

### 1. Liver CT Dataset (Unpublished)
- **Task:** Liver lesion classification
- **Views:** Arterial, Venous, Delay phases
- **Classes:** 4 (Benign, Ambiguous, Malignant, HCC)

### 2. VinDr-Mammo
- **Task:** Breast lesion classification
- **Views:** CC (Craniocaudal), MLO (Mediolateral Oblique)
- **Classes:** 3 (Normal, Benign, Malignant)
- **Samples:** ~20,000 mammograms

### 3. BreastDM
- **Task:** Breast lesion detection
- **Views:** Pre-contrast, Post-contrast, Subtraction
- **Classes:** 2 (Benign, Malignant)
- **Samples:** ~500 patients

See [docs/datasets.md](docs/datasets.md) for detailed information on data preparation.

## ğŸ—ï¸ Model Architecture

### Heterogeneous Graph Structure

**Node Types:**
- `tumor`: Tumor nodes with concatenated multi-phase features (769Ã—V dimensions)
- `phase_1`, `phase_2`, ...: Individual phase/view nodes (769 dimensions each)

**Edge Types:**
- `alpha`: Tumor â†” Phase connections (self-loops for aggregation)
- `beta`: Phase â†” Phase connections (within same tumor)
- `delta`: Same phase across different tumors (global dependencies)
- `gamma`: Tumor â†” Tumor connections (patient-level patterns)

### Feature Extraction

1. **ConvNeXt-Tiny** pretrained on ImageNet
2. Input: 224Ã—224 RGB images â†’ 768-dim features
3. Add learnable bias term â†’ 769-dim
4. L2 normalization for stability

### Missing View Imputation

Four strategies to handle missing views:

| Method | Description | Use Case |
|--------|-------------|----------|
| **Constant** | Zero vector | Baseline |
| **Learnable** | Trained embedding per view | Simple, effective |
| **RAG** | Retrieval from training database | Knowledge-based |
| **Covariance** | Covariance-based prediction | Statistical |

## ğŸ§ª Experiments

### Reproducing Paper Results

```bash
# Liver CT experiments
python scripts/train.py --config configs/liver_ct.yaml

# VinDr-Mammo experiments
python scripts/train.py --config configs/vin_dr_mammo.yaml

# BreastDM experiments
python scripts/train.py --config configs/breastdm.yaml
```

### Ablation Studies

Run ablation studies with provided configurations:

```bash
# Test different imputation methods
python scripts/train.py --config configs/ablation/imputation.yaml

# Test graph architectures
python scripts/train.py --config configs/ablation/architecture.yaml
```

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@inproceedings{giim2026,
  title={GIIM: Graph-based Learning of Inter- and Intra-view Dependencies for Multi-view Medical Image Diagnosis},
  author={Tran Bao Sam, Hung Vu, Dao Trung Kien, Dat Dang, Ha Tang, Steven Truong},
  booktitle={Proceedings of The 40th Annual AAAI Conference on Artificial Intelligence (AAAI-26)},
  year={2026},
  note={Submitted August 2025. Expected publication January 2026},
  keywords={Computer-Aided Diagnosis, Graph Neural Networks, Multi-view Medical Imaging, Missing Data Imputation, Heterogeneous Graphs, Medical Image Analysis, CT, MRI, Mammography}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### Third-Party Licenses

This software uses the following third-party libraries:
- **PyTorch** (BSD-3-Clause License)
- **PyTorch Geometric** (MIT License)
- **timm** (Apache License 2.0)
- **NumPy** (BSD License)
- **pandas** (BSD 3-Clause License)
- **scikit-learn** (BSD License)

All third-party licenses are respected and included in distributions.

## ğŸ™ Acknowledgments

- **ConvNeXt** architecture from [Facebook Research](https://github.com/facebookresearch/ConvNeXt)
- **PyTorch Geometric** for heterogeneous graph support
- Medical imaging datasets provided by [respective institutions]
- Funding support from [grant information if applicable]

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Areas for Contribution

- ğŸ› Bug fixes and improvements
- ğŸ“š Documentation enhancements
- ğŸ§ª Additional test coverage
- ğŸ¨ Visualization tools
- ğŸ“Š Support for new datasets
- ğŸ”¬ Novel imputation methods

## ğŸ“ Contact

For questions, issues, or collaboration:

- **Issues:** [GitHub Issues](https://github.com/yourusername/giim/issues)
- **Discussions:** [GitHub Discussions](https://github.com/yourusername/giim/discussions)
- **Email:** [sbtran@nvidia.com]

## ğŸ—ºï¸ Roadmap

### Phase 1: Documentation & Review (Current)
- [x] Complete documentation and architecture details
- [x] Configuration files and examples
- [x] License and citation information
- [ ] Institutional review and approval

### Phase 2: Core Release
- [ ] Model implementation (GNN, graph builder, feature extractor)
- [ ] Training and evaluation code
- [ ] Data loaders and preprocessing utilities
- [ ] Training scripts and examples
- [ ] Unit and integration tests
- [ ] Pre-trained model weights

---

**Version:** 0.0.0 (Pre-release)  
**Last Updated:** November 2025  
**Paper Submitted:** August 2025  
**Expected Publication:** January 2026  
**Status:** ğŸ“ Documentation Complete | â³ Implementation Pending Review

<p align="center">
  Made with â¤ï¸ by the VRDC Research Team (NVIDIA)
</p>
